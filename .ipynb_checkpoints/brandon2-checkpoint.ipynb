{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34798621-188c-4d59-81fc-b3b3f2d39f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS AND READ CSV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Initialise dataframe with headers\n",
    "col_names = [\"elevation\", \"aspect\", \"slope\", \"horizontaltohydro\", \"verticaltohydro\", \"horizontaltoroadway\", \"hillshade9am\", \"hillshadenoon\", \"hillshade3pm\", \"horizontaltofirepoints\", \"wildernessareaRawah\", \"wildernessareaNeota\", \"wildernessareaComanche\", \"wildernessareaCache\", \"soil1\", \"soi2\", \"soil3\", \"soil4\", \"soil5\", \"soil6\", \"soil7\", \"soil8\", \"soil9\", \"soil10\", \"soil11\", \"soil12\", \"soil13\", \"soil14\", \"soil15\", \"soil16\", \"soil17\", \"soil18\", \"soil19\", \"soil20\", \"soil21\", \"soil22\", \"soil23\", \"soil24\", \"soil25\", \"soil26\", \"soil27\", \"soil28\", \"soil29\", \"soil30\", \"soil31\", \"soil32\", \"soil33\", \"soil34\", \"soil35\", \"soil36\", \"soil37\", \"soil38\", \"soil39\", \"soil40\", \"target\"]\n",
    "cover_data = pd.read_csv('covtype.data', sep=',', names=col_names)\n",
    "# Output dataframe contains 8124 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c77b5f1-20a0-437d-91ba-928c8030294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA CLEANING\n",
    "# Remove rows with ANY null values\n",
    "X1 = cover_data.dropna()\n",
    "# Output dataframe contains 581012 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8537ae8-8685-4df7-8d66-a65832a8c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaned training and target data, ready to encode, split, and train\n",
    "\n",
    "# Training data without the target column\n",
    "X = X1.drop(columns=[\"target\"])\n",
    "\n",
    "# Initialise target column  in new dataframe\n",
    "Y = X1[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "600d5cce-5488-4d1c-a452-61e4bbb3c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e01176ed-f285-4825-96a7-691a102302e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e70940-fd21-4231-bfc0-80e337264d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for no cross validation training\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5701cbcb-d2bb-4cae-8928-97312675b12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.5 s\n",
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7165219486588126"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SGD Linear Support Vector Classifier - No Cross Validation -  max_iter = 1000\n",
    "clfSGD = make_pipeline(StandardScaler(), SGDClassifier(loss='hinge'))\n",
    "\n",
    "clfSGD.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfSGD.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "svc_NoCV_1k = accuracy\n",
    "svc_NoCV_1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de30c66d-f9fb-405c-84a3-4c92040c9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.2 s\n",
      "Wall time: 10.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7113241482577902"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SGD Logistic Regression Classifier - No Cross Validation - max_iter = 1000\n",
    "clfSGDLR = make_pipeline(StandardScaler(), SGDClassifier(loss='log_loss'))\n",
    "clfSGDLR.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfSGDLR.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "lr_NoCV_1k = accuracy\n",
    "lr_NoCV_1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a963a869-5ad7-45de-ab51-94d24402c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6759319816873773\n",
      "0.8422257409383498\n",
      "0.7288514827627751\n",
      "0.6937057881964166\n",
      "0.5804547253919898\n",
      "0.6488700710831139\n",
      "0.6739470921326656\n",
      "0.7264246742741088\n",
      "0.5635014887867679\n",
      "0.5842412350906181\n",
      "avg:0.6718154280344184\n",
      "CPU times: total: 2min 6s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 10-fold Cross-validation loss hinge (linear SVC) - max_iter = 1000\n",
    "accuracy_array_10 = []\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGD.fit(X_train, Y_train)\n",
    "    predict = clfSGD.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_10.append(accuracy)\n",
    "\n",
    "average_accuracy_10 = sum(accuracy_array_10)/k\n",
    "svc_10fold_1k = average_accuracy_10\n",
    "print(\"avg:\" + str(svc_10fold_1k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4b215d-3ee0-4ab7-82a6-573b98340729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7461683433302067\n",
      "0.7113155426279872\n",
      "0.5950672105471506\n",
      "0.6855906094559474\n",
      "0.5898951825269789\n",
      "avg:0.6656073776976541\n",
      "CPU times: total: 59.5 s\n",
      "Wall time: 52.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 5-fold Cross-validation loss hinge (linear SVC) - max iter = 1000\n",
    "accuracy_array_5 = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGD.fit(X_train, Y_train)\n",
    "    predict = clfSGD.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_5.append(accuracy)\n",
    "\n",
    "average_accuracy_5 = sum(accuracy_array_5)/k\n",
    "svc_5fold_1k = average_accuracy_5\n",
    "print(\"avg:\" + str(svc_5fold_1k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59429570-4ec7-4c07-a1c5-63906319cabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6839695707548793\n",
      "0.8361674296926096\n",
      "0.7102975852394967\n",
      "0.7107450818402438\n",
      "0.5442419235469269\n",
      "0.6203163456739127\n",
      "0.6965284590626667\n",
      "0.7455121254367395\n",
      "0.5825889399493984\n",
      "0.6200753859658181\n",
      "avg:0.6750442847162692\n",
      "CPU times: total: 2min 10s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 10-fold Cross-validation logistic regression - max iter = 1000\n",
    "accuracy_array_10 = []\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGDLR.fit(X_train, Y_train)\n",
    "    predict = clfSGDLR.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_10.append(accuracy)\n",
    "\n",
    "average_accuracy_10 = sum(accuracy_array_10)/k\n",
    "lr_10fold_1k = average_accuracy_10\n",
    "print(\"avg:\" + str(lr_10fold_1k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0a637c-854b-462d-8c2a-a82acde6acc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757932239270931\n",
      "0.7125805702090308\n",
      "0.5850415655496463\n",
      "0.6781897041359013\n",
      "0.5790778127743068\n",
      "avg:0.6625643783879632\n",
      "CPU times: total: 1min\n",
      "Wall time: 53.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 5-fold Cross-validation logistic regression - max iter = 1000\n",
    "accuracy_array_5 = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGDLR.fit(X_train, Y_train)\n",
    "    predict = clfSGDLR.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_5.append(accuracy)\n",
    "\n",
    "average_accuracy_5 = sum(accuracy_array_5)/k\n",
    "lr_5fold_1k = average_accuracy_5\n",
    "print(\"avg:\" + str(lr_5fold_1k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f42026e-4c60-4b4a-8094-202872b9fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for no cross validation training\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfcb8fe-6576-4610-b536-5f61f5b2efae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.4 s\n",
      "Wall time: 11.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7135530063767717"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SGD Linear Support Vector Classifier - No Cross Validation - max_iter = 500\n",
    "clfSGD500 = make_pipeline(StandardScaler(), SGDClassifier(loss='hinge',max_iter=500))\n",
    "\n",
    "clfSGD500.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfSGD500.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "svc_NoCV_500 = accuracy\n",
    "svc_NoCV_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75f0ef9-57a0-44f4-b4ca-65bc5880bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.8 s\n",
      "Wall time: 10.6 s\n",
      "Compiler : 125 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.713742330232438"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SGD Logistic Regression Classifier - No Cross Validation - max_iter = 500\n",
    "clfSGDLR500 = make_pipeline(StandardScaler(), SGDClassifier(loss='log_loss',max_iter=500))\n",
    "\n",
    "clfSGDLR500.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfSGDLR500.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "lr_NoCV_500 = accuracy\n",
    "lr_NoCV_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f689daa7-6819-434f-888a-083ff553b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6744862483219166\n",
      "0.8421224742693884\n",
      "0.7245830536479578\n",
      "0.6935853083423693\n",
      "0.6329323075334332\n",
      "0.614498889864202\n",
      "0.6945491471747475\n",
      "0.7179910844908005\n",
      "0.5514707147897626\n",
      "0.5811431817008313\n",
      "avg:0.6727362410135409\n",
      "CPU times: total: 2min 5s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 10-fold Cross-validation loss hinge (linear SVC) - max_iter = 500\n",
    "accuracy_array_10 = []\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGD500.fit(X_train, Y_train)\n",
    "    predict = clfSGD500.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_10.append(accuracy)\n",
    "\n",
    "average_accuracy_10 = sum(accuracy_array_10)/k\n",
    "svc_10fold_500 = average_accuracy_10\n",
    "print(\"avg:\" + str(svc_10fold_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d27c2e1-a5a7-4246-a61c-12e45fb3a3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7426142182215606\n",
      "0.7106356978735489\n",
      "0.5655238291939898\n",
      "0.6964940362472246\n",
      "0.5882773102012013\n",
      "avg:0.6607090183475051\n",
      "CPU times: total: 56.9 s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 5-fold Cross-validation loss hinge (linear SVC)- max_iter = 500\n",
    "accuracy_array_5 = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGD500.fit(X_train, Y_train)\n",
    "    predict = clfSGD500.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_5.append(accuracy)\n",
    "\n",
    "average_accuracy_5 = sum(accuracy_array_5)/k\n",
    "svc_5fold_500 = average_accuracy_5\n",
    "print(\"avg:\" + str(svc_5fold_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75ec09a5-07a8-488b-aace-406f81cdf306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.709941137998692\n",
      "0.8292313517606967\n",
      "0.7264246742741088\n",
      "0.7042735925371336\n",
      "0.5702139377979725\n",
      "0.6398512934372902\n",
      "0.6855992151598079\n",
      "0.7165281148345123\n",
      "0.5715736390079345\n",
      "0.6217965267379219\n",
      "avg:0.6775433483546071\n",
      "CPU times: total: 2min 9s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 10-fold Cross-validation logistic regression - max_iter = 500\n",
    "accuracy_array_10 = []\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGDLR500.fit(X_train, Y_train)\n",
    "    predict = clfSGDLR500.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_10.append(accuracy)\n",
    "\n",
    "average_accuracy_10 = sum(accuracy_array_10)/k\n",
    "lr_10fold_500 = average_accuracy_10\n",
    "print(\"avg:\" + str(lr_10fold_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35e2d619-a094-4ce6-9ba6-bf84043fb259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7350326583651025\n",
      "0.7084068397545674\n",
      "0.598922565876663\n",
      "0.6897127416051358\n",
      "0.5961601349374366\n",
      "avg:0.6656469881077811\n",
      "CPU times: total: 58.9 s\n",
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 5-fold Cross-validation logistic regression - max_iter = 500\n",
    "accuracy_array_5 = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGDLR500.fit(X_train, Y_train)\n",
    "    predict = clfSGDLR500.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_5.append(accuracy)\n",
    "\n",
    "average_accuracy_5 = sum(accuracy_array_5)/k\n",
    "lr_5fold_500 = average_accuracy_5\n",
    "print(\"avg:\" + str(lr_5fold_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5cd88c7-e370-49ae-9ef8-f135255e6f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR No CV 1000: 0.7113241482577902\n",
      "LR No CV 500: 0.713742330232438\n",
      "LR 5Fold 1000: 0.6625643783879632\n",
      "LR 5Fold 500: 0.6656469881077811\n",
      "LR 10fold 1000: 0.6750442847162692\n",
      "LR 10fold 500: 0.6775433483546071\n",
      "SVC No CV 1000: 0.7165219486588126\n",
      "SVC No CV 500: 0.7135530063767717\n",
      "SVC 5fold 1000: 0.6656073776976541\n",
      "SVC 5fold 500: 0.6607090183475051\n",
      "SVC 10fold 1000: 0.6718154280344184\n",
      "SVC 10fold 500: 0.6727362410135409\n"
     ]
    }
   ],
   "source": [
    "print(\"LR No CV 1000: \" + str(lr_NoCV_1k))\n",
    "print(\"LR No CV 500: \" + str(lr_NoCV_500))\n",
    "print(\"LR 5Fold 1000: \" + str(lr_5fold_1k))\n",
    "print(\"LR 5Fold 500: \" + str(lr_5fold_500))\n",
    "print(\"LR 10fold 1000: \" + str(lr_10fold_1k))\n",
    "print(\"LR 10fold 500: \" + str(lr_10fold_500))\n",
    "\n",
    "print(\"SVC No CV 1000: \" + str(svc_NoCV_1k))\n",
    "print(\"SVC No CV 500: \" + str(svc_NoCV_500))\n",
    "print(\"SVC 5fold 1000: \" + str(svc_5fold_1k))\n",
    "print(\"SVC 5fold 500: \" + str(svc_5fold_500))\n",
    "print(\"SVC 10fold 1000: \" + str(svc_10fold_1k))\n",
    "print(\"SVC 10fold 500: \" + str(svc_10fold_500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a404f96-513e-4b01-9a6e-d33c1af063d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4dde12b-0d74-4425-96b9-d58a7a7339e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc50519e-1510-48bb-bdc1-27d75d8465d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GridSearchCV Hyperparameter searching\n",
    "clfNoParams = SGDClassifier(random_state = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a0c3696-2b74-4af8-aa7c-520ce4ba6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search Space\n",
    "search_space = {\n",
    "    \"loss\" : [\"hinge\", \"log_loss\"],\n",
    "    \"max_iter\" : [500, 1000],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"elasticnet\"],\n",
    "    \"learning_rate\" : [\"optimal\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ab7b1af-7b46-4980-9c0c-c8a468168634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "### Create a GridSearchCV with 10-fold cross-validation, score by accuracy\n",
    "GS = GridSearchCV(estimator = clfNoParams,\n",
    "                  param_grid = search_space,\n",
    "                  scoring = [\"accuracy\"],\n",
    "                  refit = \"accuracy\",\n",
    "                  cv = 10,\n",
    "                  verbose = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96c85a29-d835-4440-a01a-50ab7440f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.710) total time=   9.7s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.716) total time=   9.7s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=   8.5s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.716) total time=   8.4s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.708) total time=   9.0s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.713) total time=   8.7s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.715) total time=   8.6s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.711) total time=   9.3s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.709) total time=   8.7s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.708) total time=   8.9s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  23.6s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.718) total time=  23.6s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.711) total time=  24.2s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.717) total time=  21.2s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.711) total time=  23.8s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.706) total time=  17.8s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  19.8s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  20.1s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  24.8s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.714) total time=  24.6s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.712) total time=  12.2s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.716) total time=  13.1s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.711) total time=  12.4s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.713) total time=  12.5s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.709) total time=  12.2s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.711) total time=  12.6s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.711) total time=  12.7s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.712) total time=  12.5s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.709) total time=  12.0s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.709) total time=  12.9s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.710) total time=   8.3s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.716) total time=   8.6s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   8.1s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.716) total time=   8.1s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.708) total time=   8.3s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.713) total time=   8.4s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.715) total time=   8.2s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.711) total time=   8.3s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.709) total time=   8.1s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.708) total time=   8.5s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  22.3s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.718) total time=  22.2s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.711) total time=  23.5s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.717) total time=  20.1s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.711) total time=  23.8s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.706) total time=  18.3s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  20.0s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  20.3s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  24.6s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.714) total time=  25.4s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.712) total time=  12.7s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.716) total time=  14.0s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.711) total time=  13.4s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.713) total time=  13.8s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.709) total time=  13.0s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.711) total time=  12.9s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.711) total time=  13.0s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.712) total time=  12.7s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.709) total time=  12.7s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.709) total time=  13.6s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=  10.5s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.713) total time=   8.8s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.714) total time=   8.6s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.719) total time=   8.7s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.710) total time=   8.6s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=   8.9s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=   9.0s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.709) total time=   9.5s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.710) total time=   8.8s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=   8.7s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.714) total time=  23.6s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.716) total time=  25.4s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.714) total time=  29.6s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.719) total time=  22.9s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  27.6s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.713) total time=  15.8s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.714) total time=  23.5s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.711) total time=  21.0s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  25.2s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.713) total time=  21.1s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.714) total time=  11.5s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.716) total time=  13.1s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.714) total time=  12.5s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.720) total time=  12.1s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.711) total time=  11.6s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.715) total time=  12.7s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.716) total time=  12.2s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.715) total time=  12.6s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.713) total time=  12.7s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.714) total time=  12.9s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   9.3s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.713) total time=   9.1s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.714) total time=   8.7s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.719) total time=   8.6s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.710) total time=   8.5s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   9.3s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   8.8s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.709) total time=   9.1s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.710) total time=   8.7s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   8.6s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.714) total time=  23.1s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.716) total time=  24.9s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.714) total time=  30.0s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.719) total time=  24.3s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  29.3s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.713) total time=  16.0s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.714) total time=  24.5s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.711) total time=  22.6s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  26.2s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.713) total time=  23.1s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.714) total time=  11.7s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.716) total time=  11.4s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.714) total time=  12.2s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.720) total time=  13.8s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.711) total time=  13.1s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.715) total time=  12.6s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.716) total time=  12.1s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.715) total time=  12.1s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.713) total time=  12.1s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.714) total time=  12.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=SGDClassifier(random_state=999),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [&#x27;optimal&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;], &#x27;max_iter&#x27;: [500, 1000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;]},\n",
       "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;], verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=SGDClassifier(random_state=999),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [&#x27;optimal&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;], &#x27;max_iter&#x27;: [500, 1000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;]},\n",
       "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;], verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=999)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=999)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDClassifier(random_state=999),\n",
       "             param_grid={'learning_rate': ['optimal'],\n",
       "                         'loss': ['hinge', 'log_loss'], 'max_iter': [500, 1000],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet']},\n",
       "             refit='accuracy', scoring=['accuracy'], verbose=4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18400632-dbb4-475b-b24a-c3b4a60a811b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 'optimal',\n",
       " 'loss': 'log_loss',\n",
       " 'max_iter': 500,\n",
       " 'penalty': 'elasticnet'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "238e6859-991a-4b66-90c9-9365bc05bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7146569859518414"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20340e07-d2e0-4c94-93cc-b72be508d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfBest = SGDClassifier(loss=\"log_loss\",max_iter=500,penalty=\"elasticnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fad4df2-4323-4611-afd0-5b4124ac7241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14 s\n",
      "Wall time: 13.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.715756047606344"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clfBest.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfBest.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
