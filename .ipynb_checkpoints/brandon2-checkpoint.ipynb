{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34798621-188c-4d59-81fc-b3b3f2d39f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS AND READ CSV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Initialise dataframe with headers\n",
    "col_names = [\"elevation\", \"aspect\", \"slope\", \"horizontaltohydro\", \"verticaltohydro\", \"horizontaltoroadway\", \"hillshade9am\", \"hillshadenoon\", \"hillshade3pm\", \"horizontaltofirepoints\", \"wildernessareaRawah\", \"wildernessareaNeota\", \"wildernessareaComanche\", \"wildernessareaCache\", \"soil1\", \"soi2\", \"soil3\", \"soil4\", \"soil5\", \"soil6\", \"soil7\", \"soil8\", \"soil9\", \"soil10\", \"soil11\", \"soil12\", \"soil13\", \"soil14\", \"soil15\", \"soil16\", \"soil17\", \"soil18\", \"soil19\", \"soil20\", \"soil21\", \"soil22\", \"soil23\", \"soil24\", \"soil25\", \"soil26\", \"soil27\", \"soil28\", \"soil29\", \"soil30\", \"soil31\", \"soil32\", \"soil33\", \"soil34\", \"soil35\", \"soil36\", \"soil37\", \"soil38\", \"soil39\", \"soil40\", \"target\"]\n",
    "cover_data = pd.read_csv('covtype.data', sep=',', names=col_names)\n",
    "# Output dataframe contains 8124 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c77b5f1-20a0-437d-91ba-928c8030294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA CLEANING\n",
    "# Remove rows with ANY null values\n",
    "X1 = cover_data.dropna()\n",
    "# Output dataframe contains 581012 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8537ae8-8685-4df7-8d66-a65832a8c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaned training and target data, ready to encode, split, and train\n",
    "\n",
    "# Training data without the target column\n",
    "X = X1.drop(columns=[\"target\"])\n",
    "\n",
    "# Initialise target column  in new dataframe\n",
    "Y = X1[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "600d5cce-5488-4d1c-a452-61e4bbb3c2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e01176ed-f285-4825-96a7-691a102302e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e70940-fd21-4231-bfc0-80e337264d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for no cross validation training\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5701cbcb-d2bb-4cae-8928-97312675b12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.5 s\n",
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7165219486588126"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SGD Linear Support Vector Classifier - No Cross Validation -  max_iter = 1000\n",
    "clfSGD = make_pipeline(StandardScaler(), SGDClassifier(loss='hinge'))\n",
    "\n",
    "clfSGD.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfSGD.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "svc_NoCV_1k = accuracy\n",
    "svc_NoCV_1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de30c66d-f9fb-405c-84a3-4c92040c9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.2 s\n",
      "Wall time: 10.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7113241482577902"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SGD Logistic Regression Classifier - No Cross Validation - max_iter = 1000\n",
    "clfSGDLR = make_pipeline(StandardScaler(), SGDClassifier(loss='log_loss'))\n",
    "clfSGDLR.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfSGDLR.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "lr_NoCV_1k = accuracy\n",
    "lr_NoCV_1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a963a869-5ad7-45de-ab51-94d24402c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6759319816873773\n",
      "0.8422257409383498\n",
      "0.7288514827627751\n",
      "0.6937057881964166\n",
      "0.5804547253919898\n",
      "0.6488700710831139\n",
      "0.6739470921326656\n",
      "0.7264246742741088\n",
      "0.5635014887867679\n",
      "0.5842412350906181\n",
      "avg:0.6718154280344184\n",
      "CPU times: total: 2min 6s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 10-fold Cross-validation loss hinge (linear SVC) - max_iter = 1000\n",
    "accuracy_array_10 = []\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGD.fit(X_train, Y_train)\n",
    "    predict = clfSGD.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_10.append(accuracy)\n",
    "\n",
    "average_accuracy_10 = sum(accuracy_array_10)/k\n",
    "svc_10fold_1k = average_accuracy_10\n",
    "print(\"avg:\" + str(svc_10fold_1k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4b215d-3ee0-4ab7-82a6-573b98340729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7461683433302067\n",
      "0.7113155426279872\n",
      "0.5950672105471506\n",
      "0.6855906094559474\n",
      "0.5898951825269789\n",
      "avg:0.6656073776976541\n",
      "CPU times: total: 59.5 s\n",
      "Wall time: 52.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 5-fold Cross-validation loss hinge (linear SVC) - max iter = 1000\n",
    "accuracy_array_5 = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGD.fit(X_train, Y_train)\n",
    "    predict = clfSGD.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_5.append(accuracy)\n",
    "\n",
    "average_accuracy_5 = sum(accuracy_array_5)/k\n",
    "svc_5fold_1k = average_accuracy_5\n",
    "print(\"avg:\" + str(svc_5fold_1k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59429570-4ec7-4c07-a1c5-63906319cabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6839695707548793\n",
      "0.8361674296926096\n",
      "0.7102975852394967\n",
      "0.7107450818402438\n",
      "0.5442419235469269\n",
      "0.6203163456739127\n",
      "0.6965284590626667\n",
      "0.7455121254367395\n",
      "0.5825889399493984\n",
      "0.6200753859658181\n",
      "avg:0.6750442847162692\n",
      "CPU times: total: 2min 10s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 10-fold Cross-validation logistic regression - max iter = 1000\n",
    "accuracy_array_10 = []\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGDLR.fit(X_train, Y_train)\n",
    "    predict = clfSGDLR.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_10.append(accuracy)\n",
    "\n",
    "average_accuracy_10 = sum(accuracy_array_10)/k\n",
    "lr_10fold_1k = average_accuracy_10\n",
    "print(\"avg:\" + str(lr_10fold_1k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0a637c-854b-462d-8c2a-a82acde6acc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757932239270931\n",
      "0.7125805702090308\n",
      "0.5850415655496463\n",
      "0.6781897041359013\n",
      "0.5790778127743068\n",
      "avg:0.6625643783879632\n",
      "CPU times: total: 1min\n",
      "Wall time: 53.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 5-fold Cross-validation logistic regression - max iter = 1000\n",
    "accuracy_array_5 = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGDLR.fit(X_train, Y_train)\n",
    "    predict = clfSGDLR.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_5.append(accuracy)\n",
    "\n",
    "average_accuracy_5 = sum(accuracy_array_5)/k\n",
    "lr_5fold_1k = average_accuracy_5\n",
    "print(\"avg:\" + str(lr_5fold_1k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f42026e-4c60-4b4a-8094-202872b9fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for no cross validation training\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfcb8fe-6576-4610-b536-5f61f5b2efae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.4 s\n",
      "Wall time: 11.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7135530063767717"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SGD Linear Support Vector Classifier - No Cross Validation - max_iter = 500\n",
    "clfSGD500 = make_pipeline(StandardScaler(), SGDClassifier(loss='hinge',max_iter=500))\n",
    "\n",
    "clfSGD500.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfSGD500.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "svc_NoCV_500 = accuracy\n",
    "svc_NoCV_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75f0ef9-57a0-44f4-b4ca-65bc5880bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.8 s\n",
      "Wall time: 10.6 s\n",
      "Compiler : 125 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.713742330232438"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SGD Logistic Regression Classifier - No Cross Validation - max_iter = 500\n",
    "clfSGDLR500 = make_pipeline(StandardScaler(), SGDClassifier(loss='log_loss',max_iter=500))\n",
    "\n",
    "clfSGDLR500.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfSGDLR500.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "lr_NoCV_500 = accuracy\n",
    "lr_NoCV_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f689daa7-6819-434f-888a-083ff553b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6744862483219166\n",
      "0.8421224742693884\n",
      "0.7245830536479578\n",
      "0.6935853083423693\n",
      "0.6329323075334332\n",
      "0.614498889864202\n",
      "0.6945491471747475\n",
      "0.7179910844908005\n",
      "0.5514707147897626\n",
      "0.5811431817008313\n",
      "avg:0.6727362410135409\n",
      "CPU times: total: 2min 5s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 10-fold Cross-validation loss hinge (linear SVC) - max_iter = 500\n",
    "accuracy_array_10 = []\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGD500.fit(X_train, Y_train)\n",
    "    predict = clfSGD500.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_10.append(accuracy)\n",
    "\n",
    "average_accuracy_10 = sum(accuracy_array_10)/k\n",
    "svc_10fold_500 = average_accuracy_10\n",
    "print(\"avg:\" + str(svc_10fold_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d27c2e1-a5a7-4246-a61c-12e45fb3a3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7426142182215606\n",
      "0.7106356978735489\n",
      "0.5655238291939898\n",
      "0.6964940362472246\n",
      "0.5882773102012013\n",
      "avg:0.6607090183475051\n",
      "CPU times: total: 56.9 s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 5-fold Cross-validation loss hinge (linear SVC)- max_iter = 500\n",
    "accuracy_array_5 = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGD500.fit(X_train, Y_train)\n",
    "    predict = clfSGD500.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_5.append(accuracy)\n",
    "\n",
    "average_accuracy_5 = sum(accuracy_array_5)/k\n",
    "svc_5fold_500 = average_accuracy_5\n",
    "print(\"avg:\" + str(svc_5fold_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75ec09a5-07a8-488b-aace-406f81cdf306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.709941137998692\n",
      "0.8292313517606967\n",
      "0.7264246742741088\n",
      "0.7042735925371336\n",
      "0.5702139377979725\n",
      "0.6398512934372902\n",
      "0.6855992151598079\n",
      "0.7165281148345123\n",
      "0.5715736390079345\n",
      "0.6217965267379219\n",
      "avg:0.6775433483546071\n",
      "CPU times: total: 2min 9s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 10-fold Cross-validation logistic regression - max_iter = 500\n",
    "accuracy_array_10 = []\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGDLR500.fit(X_train, Y_train)\n",
    "    predict = clfSGDLR500.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_10.append(accuracy)\n",
    "\n",
    "average_accuracy_10 = sum(accuracy_array_10)/k\n",
    "lr_10fold_500 = average_accuracy_10\n",
    "print(\"avg:\" + str(lr_10fold_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35e2d619-a094-4ce6-9ba6-bf84043fb259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7350326583651025\n",
      "0.7084068397545674\n",
      "0.598922565876663\n",
      "0.6897127416051358\n",
      "0.5961601349374366\n",
      "avg:0.6656469881077811\n",
      "CPU times: total: 58.9 s\n",
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 5-fold Cross-validation logistic regression - max_iter = 500\n",
    "accuracy_array_5 = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clfSGDLR500.fit(X_train, Y_train)\n",
    "    predict = clfSGDLR500.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, predict)\n",
    "    print(accuracy)\n",
    "    accuracy_array_5.append(accuracy)\n",
    "\n",
    "average_accuracy_5 = sum(accuracy_array_5)/k\n",
    "lr_5fold_500 = average_accuracy_5\n",
    "print(\"avg:\" + str(lr_5fold_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5cd88c7-e370-49ae-9ef8-f135255e6f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR No CV 1000: 0.7113241482577902\n",
      "LR No CV 500: 0.713742330232438\n",
      "LR 5Fold 1000: 0.6625643783879632\n",
      "LR 5Fold 500: 0.6656469881077811\n",
      "LR 10fold 1000: 0.6750442847162692\n",
      "LR 10fold 500: 0.6775433483546071\n",
      "SVC No CV 1000: 0.7165219486588126\n",
      "SVC No CV 500: 0.7135530063767717\n",
      "SVC 5fold 1000: 0.6656073776976541\n",
      "SVC 5fold 500: 0.6607090183475051\n",
      "SVC 10fold 1000: 0.6718154280344184\n",
      "SVC 10fold 500: 0.6727362410135409\n"
     ]
    }
   ],
   "source": [
    "print(\"LR No CV 1000: \" + str(lr_NoCV_1k))\n",
    "print(\"LR No CV 500: \" + str(lr_NoCV_500))\n",
    "print(\"LR 5Fold 1000: \" + str(lr_5fold_1k))\n",
    "print(\"LR 5Fold 500: \" + str(lr_5fold_500))\n",
    "print(\"LR 10fold 1000: \" + str(lr_10fold_1k))\n",
    "print(\"LR 10fold 500: \" + str(lr_10fold_500))\n",
    "\n",
    "print(\"SVC No CV 1000: \" + str(svc_NoCV_1k))\n",
    "print(\"SVC No CV 500: \" + str(svc_NoCV_500))\n",
    "print(\"SVC 5fold 1000: \" + str(svc_5fold_1k))\n",
    "print(\"SVC 5fold 500: \" + str(svc_5fold_500))\n",
    "print(\"SVC 10fold 1000: \" + str(svc_10fold_1k))\n",
    "print(\"SVC 10fold 500: \" + str(svc_10fold_500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a404f96-513e-4b01-9a6e-d33c1af063d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4dde12b-0d74-4425-96b9-d58a7a7339e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc50519e-1510-48bb-bdc1-27d75d8465d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GridSearchCV Hyperparameter searching\n",
    "clfNoParams = SGDClassifier(random_state = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a0c3696-2b74-4af8-aa7c-520ce4ba6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search Space\n",
    "search_space = {\n",
    "    \"loss\" : [\"hinge\", \"log_loss\"],\n",
    "    \"max_iter\" : [500, 1000],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"elasticnet\"],\n",
    "    \"learning_rate\" : [\"optimal\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ab7b1af-7b46-4980-9c0c-c8a468168634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "### Create a GridSearchCV with 10-fold cross-validation, score by accuracy\n",
    "GS = GridSearchCV(estimator = clfNoParams,\n",
    "                  param_grid = search_space,\n",
    "                  scoring = [\"accuracy\"],\n",
    "                  refit = \"accuracy\",\n",
    "                  cv = 10,\n",
    "                  verbose = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96c85a29-d835-4440-a01a-50ab7440f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.710) total time=   9.7s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.716) total time=   9.7s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=   8.5s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.716) total time=   8.4s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.708) total time=   9.0s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.713) total time=   8.7s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.715) total time=   8.6s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.711) total time=   9.3s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.709) total time=   8.7s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; accuracy: (test=0.708) total time=   8.9s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  23.6s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.718) total time=  23.6s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.711) total time=  24.2s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.717) total time=  21.2s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.711) total time=  23.8s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.706) total time=  17.8s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  19.8s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  20.1s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  24.8s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; accuracy: (test=0.714) total time=  24.6s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.712) total time=  12.2s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.716) total time=  13.1s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.711) total time=  12.4s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.713) total time=  12.5s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.709) total time=  12.2s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.711) total time=  12.6s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.711) total time=  12.7s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.712) total time=  12.5s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.709) total time=  12.0s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; accuracy: (test=0.709) total time=  12.9s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.710) total time=   8.3s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.716) total time=   8.6s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   8.1s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.716) total time=   8.1s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.708) total time=   8.3s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.713) total time=   8.4s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.715) total time=   8.2s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.711) total time=   8.3s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.709) total time=   8.1s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.708) total time=   8.5s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  22.3s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.718) total time=  22.2s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.711) total time=  23.5s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.717) total time=  20.1s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.711) total time=  23.8s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.706) total time=  18.3s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  20.0s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  20.3s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  24.6s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.714) total time=  25.4s\n",
      "[CV 1/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.712) total time=  12.7s\n",
      "[CV 2/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.716) total time=  14.0s\n",
      "[CV 3/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.711) total time=  13.4s\n",
      "[CV 4/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.713) total time=  13.8s\n",
      "[CV 5/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.709) total time=  13.0s\n",
      "[CV 6/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.711) total time=  12.9s\n",
      "[CV 7/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.711) total time=  13.0s\n",
      "[CV 8/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.712) total time=  12.7s\n",
      "[CV 9/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.709) total time=  12.7s\n",
      "[CV 10/10] END learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; accuracy: (test=0.709) total time=  13.6s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=  10.5s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.713) total time=   8.8s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.714) total time=   8.6s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.719) total time=   8.7s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.710) total time=   8.6s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=   8.9s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=   9.0s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.709) total time=   9.5s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.710) total time=   8.8s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; accuracy: (test=0.712) total time=   8.7s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.714) total time=  23.6s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.716) total time=  25.4s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.714) total time=  29.6s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.719) total time=  22.9s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  27.6s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.713) total time=  15.8s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.714) total time=  23.5s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.711) total time=  21.0s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.712) total time=  25.2s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; accuracy: (test=0.713) total time=  21.1s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.714) total time=  11.5s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.716) total time=  13.1s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.714) total time=  12.5s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.720) total time=  12.1s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.711) total time=  11.6s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.715) total time=  12.7s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.716) total time=  12.2s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.715) total time=  12.6s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.713) total time=  12.7s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; accuracy: (test=0.714) total time=  12.9s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   9.3s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.713) total time=   9.1s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.714) total time=   8.7s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.719) total time=   8.6s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.710) total time=   8.5s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   9.3s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   8.8s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.709) total time=   9.1s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.710) total time=   8.7s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; accuracy: (test=0.712) total time=   8.6s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.714) total time=  23.1s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.716) total time=  24.9s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.714) total time=  30.0s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.719) total time=  24.3s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  29.3s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.713) total time=  16.0s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.714) total time=  24.5s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.711) total time=  22.6s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.712) total time=  26.2s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; accuracy: (test=0.713) total time=  23.1s\n",
      "[CV 1/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.714) total time=  11.7s\n",
      "[CV 2/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.716) total time=  11.4s\n",
      "[CV 3/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.714) total time=  12.2s\n",
      "[CV 4/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.720) total time=  13.8s\n",
      "[CV 5/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.711) total time=  13.1s\n",
      "[CV 6/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.715) total time=  12.6s\n",
      "[CV 7/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.716) total time=  12.1s\n",
      "[CV 8/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.715) total time=  12.1s\n",
      "[CV 9/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.713) total time=  12.1s\n",
      "[CV 10/10] END learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; accuracy: (test=0.714) total time=  12.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=SGDClassifier(random_state=999),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [&#x27;optimal&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;], &#x27;max_iter&#x27;: [500, 1000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;]},\n",
       "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;], verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=SGDClassifier(random_state=999),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [&#x27;optimal&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;], &#x27;max_iter&#x27;: [500, 1000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;]},\n",
       "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;], verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=999)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=999)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDClassifier(random_state=999),\n",
       "             param_grid={'learning_rate': ['optimal'],\n",
       "                         'loss': ['hinge', 'log_loss'], 'max_iter': [500, 1000],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet']},\n",
       "             refit='accuracy', scoring=['accuracy'], verbose=4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18400632-dbb4-475b-b24a-c3b4a60a811b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 'optimal',\n",
       " 'loss': 'log_loss',\n",
       " 'max_iter': 500,\n",
       " 'penalty': 'elasticnet'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "238e6859-991a-4b66-90c9-9365bc05bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7146569859518414"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20340e07-d2e0-4c94-93cc-b72be508d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfBest = SGDClassifier(loss=\"log_loss\",max_iter=500,penalty=\"elasticnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fad4df2-4323-4611-afd0-5b4124ac7241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14 s\n",
      "Wall time: 13.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.715756047606344"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clfBest.fit(X_train, Y_train)\n",
    "\n",
    "predict = clfBest.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predict)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75f101c5-9399-4c70-be5b-fe2fe7c70e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "final_matrix = confusion_matrix(Y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8913e0a-1a42-4aab-a1c9-4ad3c4e3a876",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuadMesh' object has no property 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msn\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43msn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\seaborn\\matrix.py:459\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m square:\n\u001b[0;32m    458\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_aspect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m \u001b[43mplotter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_ax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ax\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\seaborn\\matrix.py:306\u001b[0m, in \u001b[0;36m_HeatMapper.plot\u001b[1;34m(self, ax, cax, kws)\u001b[0m\n\u001b[0;32m    303\u001b[0m     kws\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvmax)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;66;03m# Draw the heatmap\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m mesh \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mpcolormesh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_data, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcmap, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# Set the axis limits\u001b[39;00m\n\u001b[0;32m    309\u001b[0m ax\u001b[38;5;241m.\u001b[39mset(xlim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), ylim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6066\u001b[0m, in \u001b[0;36mAxes.pcolormesh\u001b[1;34m(self, alpha, norm, cmap, vmin, vmax, shading, antialiased, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6062\u001b[0m C \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m   6064\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnap\u001b[39m\u001b[38;5;124m'\u001b[39m, rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpcolormesh.snap\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 6066\u001b[0m collection \u001b[38;5;241m=\u001b[39m mcoll\u001b[38;5;241m.\u001b[39mQuadMesh(\n\u001b[0;32m   6067\u001b[0m     coords, antialiased\u001b[38;5;241m=\u001b[39mantialiased, shading\u001b[38;5;241m=\u001b[39mshading,\n\u001b[0;32m   6068\u001b[0m     array\u001b[38;5;241m=\u001b[39mC, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm, alpha\u001b[38;5;241m=\u001b[39malpha, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   6069\u001b[0m collection\u001b[38;5;241m.\u001b[39m_scale_norm(norm, vmin, vmax)\n\u001b[0;32m   6070\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pcolor_grid_deprecation_helper()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\matplotlib\\collections.py:2015\u001b[0m, in \u001b[0;36mQuadMesh.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bbox\u001b[38;5;241m.\u001b[39mupdate_from_data_xy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinates\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m   2013\u001b[0m \u001b[38;5;66;03m# super init delayed after own init because array kwarg requires\u001b[39;00m\n\u001b[0;32m   2014\u001b[0m \u001b[38;5;66;03m# self._coordinates and self._shading\u001b[39;00m\n\u001b[1;32m-> 2015\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2016\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmouseover \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\matplotlib\\collections.py:217\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, transOffset, norm, cmap, pickradius, hatch, urls, zorder, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transOffset \u001b[38;5;241m=\u001b[39m transOffset\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_effects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\matplotlib\\artist.py:1064\u001b[0m, in \u001b[0;36mArtist.update\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1062\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(func):\n\u001b[1;32m-> 1064\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1065\u001b[0m                                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no property \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1066\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'QuadMesh' object has no property 'x'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "x_axis_labels = [\"Spruce/Fir\",\"Lodgepole Pine\",\"Ponderosa Pine\",\"Cottonwood/Willow\",\"Aspen\",\"Douglas-fir\",\"Krummholz\"]\n",
    "cf_matrix = sn.heatmap(final_matrix, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfa84f2b-272f-4d7a-a8e1-e86903a096c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.68      0.70     42479\n",
      "           2       0.74      0.80      0.77     56554\n",
      "           3       0.62      0.85      0.72      7148\n",
      "           4       0.60      0.31      0.41       559\n",
      "           5       0.00      0.00      0.00      1938\n",
      "           6       0.42      0.08      0.14      3392\n",
      "           7       0.71      0.52      0.60      4133\n",
      "\n",
      "    accuracy                           0.72    116203\n",
      "   macro avg       0.54      0.46      0.48    116203\n",
      "weighted avg       0.70      0.72      0.70    116203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\brand\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\brand\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd3c6e-5fc2-43dc-9367-59faca9c0de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
