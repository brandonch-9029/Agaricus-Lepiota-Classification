{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34798621-188c-4d59-81fc-b3b3f2d39f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS AND READ CSV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialise dataframe with headers\n",
    "col_names = [\"elevation\", \"aspect\", \"slope\", \"horizontaltohydro\", \"verticaltohydro\", \"horizontaltoroadway\", \"hillshade9am\", \"hillshadenoon\", \"hillshade3pm\", \"horizontaltofirepoints\", \"wildernessareaRawah\", \"wildernessareaNeota\", \"wildernessareaComanche\", \"wildernessareaCache\", \"soil1\", \"soi2\", \"soil3\", \"soil4\", \"soil5\", \"soil6\", \"soil7\", \"soil8\", \"soil9\", \"soil10\", \"soil11\", \"soil12\", \"soil13\", \"soil14\", \"soil15\", \"soil16\", \"soil17\", \"soil18\", \"soil19\", \"soil20\", \"soil21\", \"soil22\", \"soil23\", \"soil24\", \"soil25\", \"soil26\", \"soil27\", \"soil28\", \"soil29\", \"soil30\", \"soil31\", \"soil32\", \"soil33\", \"soil34\", \"soil35\", \"soil36\", \"soil37\", \"soil38\", \"soil39\", \"soil40\", \"target\"]\n",
    "cover_data = pd.read_csv('covtype.data', sep=',', names=col_names)\n",
    "\n",
    "X1 = cover_data.dropna()\n",
    "X = X1.drop(columns=[\"target\"])\n",
    "Y = X1[\"target\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eec9317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before cross validation: 0.9499582626954554\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import cross_val_score, KFold \n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # before cross-validation\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "# clf = KNeighborsClassifier(n_neighbors=5, n_jobs=10)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(\"accuracy before cross validation: \" + str(accuracy_score(Y_test, Y_pred)))\n",
    "\n",
    "# # cross-validation\n",
    "# acc_scores = []\n",
    "# k = 5\n",
    "# kf = KFold(n_splits=k, random_state=None)\n",
    "# for train_index , test_index in kf.split(X):\n",
    "#     X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "#     Y_train , Y_test = Y[train_index] , Y[test_index]\n",
    "\n",
    "#     clf.fit(X_train, Y_train)\n",
    "#     Y_pred = clf.predict(X_test)\n",
    "\n",
    "#     acc = accuracy_score(Y_test , Y_pred)\n",
    "#     print(\"    \" + str(acc))\n",
    "#     acc_scores.append(acc)\n",
    "\n",
    "# # show average accuracy\n",
    "# avg_acc_score = sum(acc_scores)/k\n",
    "# print(\"average:\" + str(avg_acc_score))\n",
    "\n",
    "# # print(confusion_matrix(Y_test,Y_pred))\n",
    "# # print(classification_report(Y_test,Y_pred))\n",
    "# # print(accuracy_score(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebc7a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===RF before CV===\n",
      "[[40155  2176     1     0     5     6    91]\n",
      " [ 1283 55122   105     1    67    66    21]\n",
      " [    1    93  6851    23     6   148     0]\n",
      " [    0     0    76   474     0    14     0]\n",
      " [   37   366    17     0  1450     8     0]\n",
      " [    6   101   234    10     8  3156     0]\n",
      " [  187    23     0     0     0     0  3815]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.95      0.95     42434\n",
      "           2       0.95      0.97      0.96     56665\n",
      "           3       0.94      0.96      0.95      7122\n",
      "           4       0.93      0.84      0.88       564\n",
      "           5       0.94      0.77      0.85      1878\n",
      "           6       0.93      0.90      0.91      3515\n",
      "           7       0.97      0.95      0.96      4025\n",
      "\n",
      "    accuracy                           0.96    116203\n",
      "   macro avg       0.95      0.91      0.92    116203\n",
      "weighted avg       0.96      0.96      0.96    116203\n",
      "\n",
      "===RF after CV===\n",
      "[[40155  2176     1     0     5     6    91]\n",
      " [ 1283 55122   105     1    67    66    21]\n",
      " [    1    93  6851    23     6   148     0]\n",
      " [    0     0    76   474     0    14     0]\n",
      " [   37   366    17     0  1450     8     0]\n",
      " [    6   101   234    10     8  3156     0]\n",
      " [  187    23     0     0     0     0  3815]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.95      0.95     42434\n",
      "           2       0.95      0.97      0.96     56665\n",
      "           3       0.94      0.96      0.95      7122\n",
      "           4       0.93      0.84      0.88       564\n",
      "           5       0.94      0.77      0.85      1878\n",
      "           6       0.93      0.90      0.91      3515\n",
      "           7       0.97      0.95      0.96      4025\n",
      "\n",
      "    accuracy                           0.96    116203\n",
      "   macro avg       0.95      0.91      0.92    116203\n",
      "weighted avg       0.96      0.96      0.96    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### compare models before and after Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## Random Forest before CV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFaccuracy_scores = []\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, Y_train)\n",
    "Y_pred = RF.predict(X_test)\n",
    "RFaccuracy_scores.append(accuracy_score(Y_test, Y_pred))    # store accuracy for visualisation later\n",
    "print(\"===RF before CV===\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "## Random Forest after CV\n",
    "scores = cross_val_score(RF, X, Y, cv=5)\n",
    "RFaccuracy_scores.append(scores.mean())                     # store accuracy for visualisation later\n",
    "print(\"===RF after CV===\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "\n",
    "## kNN before CV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kNNaccuracy_scores = []\n",
    "kNN = KNeighborsClassifier(n_neighbors=5)\n",
    "kNN.fit(X_train, Y_train)\n",
    "Y_pred = kNN.predict(X_test)\n",
    "kNNaccuracy_scores.append(accuracy_score(Y_test, Y_pred))   # store accuracy for visualisation later\n",
    "print(\"===kNN before CV===\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "## kNN after CV\n",
    "scores = cross_val_score(kNN, X, Y, cv=5)\n",
    "kNNaccuracy_scores.append(scores.mean())                    # store accuracy for visualisation later            \n",
    "print(\"===kNN after CV===\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "\n",
    "## SGD before CV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "SGDaccuracy_scores = []\n",
    "SGD = make_pipeline(StandardScaler(), SGDClassifier(loss='log_loss'))\n",
    "SGD.fit(X_train, Y_train)\n",
    "Y_pred = SGD.predict(X_test)\n",
    "SGDaccuracy_scores.append(accuracy_score(Y_test, Y_pred))   # store accuracy for visualisation later \n",
    "print(\"===LR using SGD before CV===\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "## SGD after CV\n",
    "scores = cross_val_score(SGD, X, Y, cv=5)\n",
    "SGDaccuracy_scores.append(scores.mean())                    # store accuracy for visualisation later \n",
    "print(\"===LR using SGD after CV===\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42c7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95.51732743560838, 59.56882144244514]\n"
     ]
    }
   ],
   "source": [
    "# print(RFaccuracy_scores)\n",
    "# print(kNNaccuracy_scores)\n",
    "# print(SGDaccuracy_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b2ae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# plt.figure(figsize=(4, 8))\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# plt.plot([\"Before\", \"After\"], accuracy_scores, color='cyan', linestyle='dashed', marker='o',\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#          markerfacecolor='blue', markersize=10, label='RandomForest')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m# plt.xlabel('Before/After Cross Validation')\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# plt.ylabel('Accuracy Score')\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(accuracy_scores)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_scores' is not defined"
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize=(4, 8))\n",
    "# plt.plot([\"Before\", \"After\"], accuracy_scores, color='cyan', linestyle='dashed', marker='o',\n",
    "#          markerfacecolor='blue', markersize=10, label='RandomForest')\n",
    "# plt.plot([\"Before\", \"After\"], [97, 51], color='green', linestyle='dashed', marker='o',\n",
    "#          markerfacecolor='blue', markersize=10, label='kNN')   \n",
    "# plt.title('Accuracy before and after Cross Validation')\n",
    "# plt.xlabel('Before/After Cross Validation')\n",
    "# plt.ylabel('Accuracy Score')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameter tuning\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# leaf_size = list(range(1,10))\n",
    "# n_neighbors = list(range(1,10))\n",
    "# p=[1,2]\n",
    "\n",
    "# # Create new KNN object\n",
    "# kNN2 = KNeighborsClassifier()\n",
    "\n",
    "# # List Hyperparameters that we want to tune.\n",
    "# params = {\n",
    "#     \"leaf_size\": list(range(1,10)),\n",
    "#     \"n_neighbors\": list(range(1,10)),\n",
    "#     \"p\": [1,2]\n",
    "# }\n",
    "\n",
    "# # Use GridSearch\n",
    "# gs = GridSearchCV(estimator=kNN2, param_grid=params, cv=3, verbose=2, n_jobs=3)\n",
    "# best_model = gs.fit(X_train, Y_train)\n",
    "\n",
    "# # Print The value of best Hyperparameters\n",
    "# print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "# print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "# print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Logitsics Regression\n",
    "# # Train and Predict\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# lr = LogisticRegression(penalty=\"none\", max_iter=2000, n_jobs=12)\n",
    "# lr.fit(X_train, Y_train)\n",
    "\n",
    "# Y_pred = lr.predict(X_test)\n",
    "# print(confusion_matrix(Y_test, Y_pred))\n",
    "# print(classification_report(Y_test, Y_pred))\n",
    "# print(accuracy_score(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "01e9df73af7b256228df8e2ec07bd9c6061a714ff3c5c59923ec330bb1caee9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
